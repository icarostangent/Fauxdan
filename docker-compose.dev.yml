services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app 
      - ./frontend/node_modules:/app/node_modules
    environment:
      - VUE_APP_API_URL=${VUE_APP_API_URL}
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev.backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app 
      - ./static:/static
      - logs:/var/log/app
    environment:
      - DJANGO_DEBUG=True
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - DJANGO_DB_NAME=${DJANGO_DB_NAME}
      - DJANGO_DB_USER=${DJANGO_DB_USER}
      - DJANGO_DB_PASSWORD=${DJANGO_DB_PASSWORD}
      - DJANGO_DB_HOST=${DJANGO_DB_HOST}
      - DJANGO_DB_PORT=${DJANGO_DB_PORT}
    depends_on:
      - db
      - redis
    command: ["/bin/bash", "/app/init.sh"]
    restart: unless-stopped

  # New backend-admin service for admin-specific functionality
  backend-admin:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev.backend
    ports:
      - "8001:8001"
    volumes:
      - ./backend:/app 
      - ./static:/static
      - logs:/var/log/app
    environment:
      - DJANGO_DEBUG=True
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - DJANGO_DB_NAME=${DJANGO_DB_NAME}
      - DJANGO_DB_USER=${DJANGO_DB_USER}
      - DJANGO_DB_PASSWORD=${DJANGO_DB_PASSWORD}
      - DJANGO_DB_HOST=${DJANGO_DB_HOST}
      - DJANGO_DB_PORT=${DJANGO_DB_PORT}
      - DJANGO_ADMIN_PORT=8001
    depends_on:
      - db
      - redis
    command: ["/bin/bash", "/app/init.sh"]
    restart: unless-stopped
      
  scanner:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev.scanner
    volumes:
      - ./backend:/app 
      - logs:/var/log/app
    environment:
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY}
      - DJANGO_DEBUG=True
      - DJANGO_DB_NAME=${DJANGO_DB_NAME}
      - DJANGO_DB_USER=${DJANGO_DB_USER}
      - DJANGO_DB_PASSWORD=${DJANGO_DB_PASSWORD}
      - DJANGO_DB_HOST=${DJANGO_DB_HOST}
      - DJANGO_DB_PORT=${DJANGO_DB_PORT}
    depends_on:
      - db
      - redis
    restart: unless-stopped
    cap_add:
      - NET_ADMIN
    command: ["python3", "manage.py", "run_scanner_service", "--max-concurrent", "5", "--job-types", "masscan,banner_grab,ssl_cert,domain_enum"]


  db:
    build:
      context: ./db
      dockerfile: Dockerfile
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - DJANGO_DB_NAME=${DJANGO_DB_NAME}
      - DJANGO_DB_USER=${DJANGO_DB_USER}
      - DJANGO_DB_PASSWORD=${DJANGO_DB_PASSWORD}
      - DJANGO_DB_HOST=${DJANGO_DB_HOST}
    volumes:
      - db_data:/var/lib/postgresql/data
      # - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./db/init_db.sh:/docker-entrypoint-initdb.d/init_db.sh
    restart: unless-stopped

  redis:
    build:
      context: ./redis
      dockerfile: Dockerfile
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  caddy:  
    build:
      context: ./caddy
      dockerfile: Dockerfile.dev
    ports:
      - "0.0.0.0:80:80"
      - "0.0.0.0:443:443"
    volumes:
      - ./caddy/Caddyfile.dev:/etc/caddy/Caddyfile
      - ./static:/static
      - ./backend/staticfiles:/staticfiles
      - caddy_certs:/etc/caddy/certs
      - caddy_data:/data
    restart: unless-stopped

  # New caddy-admin service for admin panel routing
  caddy-admin:
    build:
      context: ./caddy
      dockerfile: Dockerfile.dev
    ports:
      - "127.0.0.1:8443:8443"
    volumes:
      - ./caddy/Caddyfile.admin.dev:/etc/caddy/Caddyfile
      - ./static:/static
      - ./backend/staticfiles:/staticfiles
      - ./monitoring/admin:/admin
      - caddy_certs:/etc/caddy/certs
      - caddy_data:/data
    restart: unless-stopped

  tor:
    image: dperson/torproxy
    ports:
      - "9050:9050"
      - "9090:9090"
    restart: unless-stopped

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9091:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'

    restart: unless-stopped

  # Grafana for dashboards and visualization (updated for admin routing)
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./monitoring/grafana/provisioning/grafana/grafana.ini:/etc/grafana/grafana.ini
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SERVER_ROOT_URL=https://localhost:8443/grafana/
      - GF_SERVER_SERVE_FROM_SUBPATH=true
    restart: unless-stopped
    depends_on:
      - prometheus

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: unless-stopped

  # Redis Exporter for Redis metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    restart: unless-stopped
    depends_on:
      - redis

  # Postgres Exporter for database metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://${DJANGO_DB_USER}:${DJANGO_DB_PASSWORD}@db:5432/${DJANGO_DB_NAME}?sslmode=disable
    restart: unless-stopped
    depends_on:
      - db

  # Elasticsearch for log storage and search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: fauxdan-elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    volumes:
      - ./monitoring/elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - elasticsearch_data:/usr/share/elasticsearch/data
      - elasticsearch_logs:/usr/share/elasticsearch/logs
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Log forwarder to send Django logs to Logstash
  log-forwarder:
    build:
      context: ./monitoring
      dockerfile: Dockerfile.log-forwarder
    container_name: fauxdan-log-forwarder
    volumes:
      - logs:/var/log/app
    environment:
      - LOG_FILE=/var/log/app/django.log
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    depends_on:
      logstash:
        condition: service_healthy
    restart: unless-stopped

  # Logstash for log processing and forwarding
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: fauxdan-logstash
    ports:
      - "5000:5000"
      - "5044:5044"
      - "514:514"
    volumes:
      - ./monitoring/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
      - ./monitoring/logstash/templates:/usr/share/logstash/templates:ro
      - logs:/var/log/app
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - logstash_data:/usr/share/logstash/data
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana for log visualization and analysis
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: fauxdan-kibana
    ports:
      - "5601:5601"
    volumes:
      - ./monitoring/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
      - kibana_data:/usr/share/kibana/data
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=""
      - ELASTICSEARCH_PASSWORD=""
    depends_on:
      elasticsearch:
        condition: service_healthy
      logstash:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  db_data:
  redis_data:
  caddy_data:
  caddy_certs:
  prometheus_data:
  grafana_data:
  elasticsearch_data:
  elasticsearch_logs:
  logstash_data:
  kibana_data:
  logs: